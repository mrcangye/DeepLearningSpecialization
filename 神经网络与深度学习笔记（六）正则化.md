# 神经网络与深度学习笔记（六）正则化

## 前言

前面提到过高方差问题主要的两种方式：

- 获取更多的数据去训练。然而这种方式局限在于，数据并不是总是很容易获得的或者数据获取的代价很大。
- 正则化。这就是这篇文章需要来讨论的主题。

## 最小化代价函数正则化

最小化代价函数：
$$
min_{(w,b)}  \jmath(w,b) = \frac{1}{m}\sum_{i=1}^m\jmath(\hat y^{(i)},y^{(i)}) + \frac{\lambda}{2m} \Arrowvert w\Arrowvert^{2}_{2}
$$
其中，$\lambda$ 称为正则化参数。在编程过程中，常常把 $\lambda$ 称为

